#!/usr/bin/python

import os
import urllib2
import lxml.etree
import lxml.html
import urlparse

# This respects http_proxy
def get_from_url(url):
    #doc = lxml.etree.parse(url) # doesn't use proxy
    #return lxml.etree.parse(urllib2.urlopen(url))
    s = urllib2.urlopen(url).read()
    #print s
    return lxml.etree.fromstring(s)

def get_html_from_url(url):
    #doc = lxml.etree.parse(url) # doesn't use proxy
    #return lxml.etree.parse(urllib2.urlopen(url))
    s = urllib2.urlopen(url).read()
    #print s
    return lxml.html.fromstring(s)

def get_place(li):
    for sp in li.xpath("span[@class=\"place\"]/text()"):
        return sp
    return None

def get_li(doc, place):
    for li in doc.xpath("li"):
        if get_place(li) == place:
            return li
    return None    

def get_ahref(li, alt):
    for a in li.xpath("a[@class=\"nav\"]"):
        for imgalt in a.xpath("img/@alt"):
            if imgalt == alt:
                return a.attrib["href"]
    return None

def get_next(url, code):
    doc = get_from_url(
        "http://lesswrong.com/api/article_navigation?article_id={0}".format(code))
    #print lxml.etree.tostring(doc)
    li = get_li(doc, "by author")
    if li is None: return None
    ahref = get_ahref(li, "Next")
    if ahref is None: return None
    return urlparse.urljoin(url, ahref)

def get_entry(url, code):
    content = get_html_from_url(url)
    #print lxml.html.tostring(content, pretty_print=True)
    for frag in content.xpath("//div[@id=\"entry_t3_{0}\"]/div/div".format(code)):
        return frag
    return None

def is_dodgy(url):
    parsed = urlparse.urlparse(url)
    if parsed.hostname and parsed.hostname.endswith("lesswrong.com"):
        return parsed.hostname != "wiki.lesswrong.com"
    if not parsed.hostname and not parsed.path.startswith("/lw/"):
        return True
    return False

def goodpath(path):
    assert len(path) == 5
    assert path[0] == ""
    assert path[1] == "lw"
    assert path[4] == ""

url = "http://lesswrong.com/lw/gn/the_martial_art_of_rationality/"
for i in range(20):
    print "    ", url
    path = urlparse.urlparse(url).path.split("/")
    goodpath(path)   
    code = path[2]
    entry = get_entry(url, code)
    
    #print lxml.html.tostring(entry, pretty_print=True)
    for a in entry.xpath(".//a"):
        if not a.attrib.has_key("href"):
            continue
        href = a.attrib["href"]
        parsed = urlparse.urlparse(href)
        if not parsed.hostname:
            hpath = parsed.path.split("/")
            goodpath(path)
            a.attrib["href"] = "../{0}/{1}.html".format(hpath[2], hpath[3])
        #if is_dodgy(href):
        #    print "href:", href
    #for src in entry.xpath(".//img/@src"):
    #    if is_dodgy(src):
    #        print "src:",src
    os.makedirs("/".join(path[1:-2]))
    with open("/".join(path[1:-1]) + ".html", "w") as f:
        f.write(lxml.html.tostring(entry))
    #print
    #print "===================================================="
    #print
    url = get_next(url, code)
    if url is None:
        break


#get_next("gn")
#url = get_next("go")
#print get_urlcode(url)

