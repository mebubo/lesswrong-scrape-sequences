#!/usr/bin/python

import urllib2
import lxml.etree
import lxml.html
import urlparse

# This respects http_proxy
def get_from_url(url):
    #doc = lxml.etree.parse(url) # doesn't use proxy
    #return lxml.etree.parse(urllib2.urlopen(url))
    s = urllib2.urlopen(url).read()
    #print s
    return lxml.etree.fromstring(s)

def get_html_from_url(url):
    #doc = lxml.etree.parse(url) # doesn't use proxy
    #return lxml.etree.parse(urllib2.urlopen(url))
    s = urllib2.urlopen(url).read()
    #print s
    return lxml.html.fromstring(s)

def get_place(li):
    for sp in li.xpath("span[@class=\"place\"]/text()"):
        return sp
    return None

def get_li(doc, place):
    for li in doc.xpath("li"):
        if get_place(li) == place:
            return li
    return None    

def get_ahref(li, alt):
    for a in li.xpath("a[@class=\"nav\"]"):
        for imgalt in a.xpath("img/@alt"):
            if imgalt == alt:
                return a.attrib["href"]

def get_next(url, code):
    doc = get_from_url(
        "http://lesswrong.com/api/article_navigation?article_id={0}".format(code))
    #print lxml.etree.tostring(doc)
    li = get_li(doc, "by author")
    return urlparse.urljoin(url, get_ahref(li, "Next"))

url = "http://lesswrong.com/lw/gn/the_martial_art_of_rationality/"
#print url
for i in range(1):
    path = urlparse.urlparse(url).path.split("/")
    code = path[2]
    content = get_html_from_url(url)
    #print lxml.html.tostring(content, pretty_print=True)
    for frag in content.xpath("//div[@id=\"entry_t3_{0}\"]".format(code)):
        print lxml.html.tostring(frag, pretty_print=True)
    url = get_next(url, code)
    #print url


#get_next("gn")
#url = get_next("go")
#print get_urlcode(url)

