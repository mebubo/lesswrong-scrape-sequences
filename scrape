#!/usr/bin/python

import itertools
import os
import lxml.html
from lxml.html import builder as E


import cachefetch
import blogpost
import sequence
import sequences

FIRST_POST = "http://lesswrong.com/lw/gn/the_martial_art_of_rationality/"
TITLE = "Eliezer Yudkowsky. Lesswrong.com blog posts, 2006-2013."

def scrape_all(start_url, sequencer):
    posts = list(collect_urls(start_url, sequencer))
    codemap = create_codemap(posts)
    read_articles(posts)
    fix_urls(posts, codemap)
    sequencelist = make_sequences(codemap)
    write_posts(posts)
    write_index(posts, sequencelist)
    sequencelist.write()
    sequencelist.save()
    print "Done"

def collect_urls(start_url, sequencer):
    print "Collecting URLs"
    url = start_url
    for seq in sequencer:
        print "...", url
        post = blogpost.Blogpost(seq, url)
        yield post
        url = post.get_nexturl()
        if url is None:
            break

def create_codemap(posts):
    return dict((p.code, p) for p in posts)

def read_articles(posts):
    print "Reading articles"
    for i, post in enumerate(posts):
        print u"{0:3}/{1:3} {2}".format(i+1, len(posts), post.url)
        post.read()

def fix_urls(posts, codemap):
    print "Fixing URLs"
    for post in posts:
        post.fix_urls(codemap)

def make_sequences(codemap):
    print "Making Sequences"
    sequence_list = sequence.SequenceList()
    for i, (title, url, xpath) in enumerate(sequences.sequences):
        print "    ", title
        seq = sequence.Sequence(title, i+1)
        lx = cachefetch.get_html_from_url(url)
        for href in lx.xpath(xpath):
            code = blogpost.urltocode(href)
            if code is not None and code in codemap:
                p = codemap[code]
                seq.append(p)
                p.addseq(seq)
            #else:
            #    print "    ", href
        sequence_list.add(seq)
    return sequence_list

def write_posts(posts):
    print "Writing posts"
    for post in posts:
        post.write()

def write_index(posts, sequencelist):
    print "Writing index"
    with open("target/index.html", "w") as f:
        f.write(lxml.html.tostring(
            E.HTML(
                E.HEAD(
                    E.TITLE(TITLE),
                ), E.BODY(
                    E.H1(TITLE),
                    E.H3("In sequence order:"),
                    E.UL(E.LI(E.A("All sequences", href="sequences.html")),
                         E.UL(*[s.li() for s in sequencelist if s.has_posts()])),
                    E.H3("In chronological order:"),
                    E.UL(*[p.li() for p in posts])
                )
            )))

def main():
    os.mkdir("target")
    sequencer = itertools.count(1)
    scrape_all(FIRST_POST, sequencer)
    #for e in sorted(blogpost.allattrs):
    #    print e

if __name__ == '__main__':
    main()
